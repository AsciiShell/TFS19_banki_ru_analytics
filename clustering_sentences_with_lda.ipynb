{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering_sentences_with_lda.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wNZf3CaK6hP9",
        "colab_type": "code",
        "outputId": "710054cf-5f19-4cde-a633-db0eeec5df4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IvhWrHXxE6X_",
        "colab_type": "code",
        "outputId": "86aca966-3239-4c16-fbaa-81b843cb35cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install pyLDAvis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.2.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.24.2)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.12.5)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.6.9)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/d1f90f4e2af5f9d4921ab3797e33cf0503e3f130dd390a812f3bf59ce9ea/funcy-1.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (40.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.11.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (7.0.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.3.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.12 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZQLPUr2l6vCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdU5bf11YJKg",
        "colab_type": "code",
        "outputId": "fb96fdf4-d34b-408e-e4b4-1d04ba42d04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from gensim.models import Phrases\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim as gensimvis\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go \n",
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "from plotly.offline import plot"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/html": [
              "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jW7dIN_f4r4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('russian'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H1O5TpsyXDpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class lda(object):\n",
        "  def __init__(self, path_to_texts, path_to_sentiment, add_bigramms=False):\n",
        "    assert os.path.exists(path_to_texts) and os.path.exists(path_to_sentiment)\n",
        "    \n",
        "    self.texts = [[word for word in line.split() if word not in stopwords] for line in pd.read_pickle(path_to_texts)['lemmatized']]\n",
        "    self.vocab = None\n",
        "    self.model = None\n",
        "    self.clusters_distribution = {}\n",
        "    self.general_statistic = {}\n",
        "    self.path_to_sentiment = path_to_sentiment\n",
        "    self.clusters_titles = None\n",
        "    \n",
        "    if add_bigramms:\n",
        "      finder = Phrases(self.texts)\n",
        "      for i in range(len(self.texts)):\n",
        "        for word in finder[self.texts[i]]:\n",
        "          if '_' in word:\n",
        "            self.texts[i].append(word)\n",
        "            \n",
        "  def create_vocab(self, no_below=5, no_above=0.5):\n",
        "    self.vocab = Dictionary(self.texts)\n",
        "    self.vocab.filter_extremes(no_below=no_below, no_above=no_above)\n",
        "  \n",
        "  def vectorize_texts(self):\n",
        "    self.texts = [self.vocab.doc2bow(sent) for sent in self.texts]\n",
        "    \n",
        "    \n",
        "  def train_ldamodel(self, num_topics, chunksize, epochs, steps, eval_every=None, id2word=None):\n",
        "    if id2word==None:\n",
        "      temp = self.vocab[0]\n",
        "      id2word = self.vocab.id2token\n",
        "    \n",
        "    self.model = LdaModel(self.texts, num_topics=num_topics, id2word=id2word, chunksize=chunksize, passes=epochs,\n",
        "                    alpha='auto', eta='auto', iterations=steps, eval_every=None)\n",
        "    \n",
        "  def write_clusterring_t0_html_file(self, title):\n",
        "    vis = gensimvis.prepare(self.model, self.texts, self.vocab)\n",
        "    with open(os.path.join('/content', title + '.html'), 'w') as file:\n",
        "      pyLDAvis.save_html(vis, file)\n",
        "      \n",
        "  def get_cluster_distribution_and_sentiment(self):\n",
        "    labels = pd.read_csv(self.path_to_sentiment)['label']\n",
        "    #ids = pd.read_csv(self.path_to_sentiment)['id']\n",
        "    for index, label in enumerate(labels):\n",
        "      if label =='negative' or label == 'positive':\n",
        "        cluster = sorted(self.model.get_document_topics(self.texts[index]), key=lambda x: x[1], reverse=True)[0][0]\n",
        "        if cluster in self.clusters_distribution:\n",
        "          self.clusters_distribution[cluster][0].append(index)\n",
        "          self.clusters_distribution[cluster][1].append(label)\n",
        "        else:\n",
        "          self.clusters_distribution[cluster] = [[index], [label]]\n",
        "  \n",
        "  def grab_general_statistic(self):\n",
        "    for k, v in self.clusters_distribution.items():\n",
        "      self.general_statistic[k] = {'positives': v[1].count('positive'), 'negatives': v[1].count('negative')}\n",
        "      \n",
        "  def return_statistics_for_ploting(self):\n",
        "    positives = [elem['positives'] for elem in self.general_statistic.values()]\n",
        "    negatives = [elem['negatives'] for elem in self.general_statistic.values()]\n",
        "    \n",
        "    return positives, negatives, self.clusters_titles\n",
        "  \n",
        "  def rename_clusters(self, names):\n",
        "    self.clusters_titles = [i for i in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ji-MrD0ZB8l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class plot_statistics(object):\n",
        "  def __init__(self, max_figures):\n",
        "    self.data = []\n",
        "    self.buttons = []\n",
        "    self.current_number_of_figures = 0\n",
        "    self.max_figures_available = max_figures\n",
        "    \n",
        "  def add_one_more_bank(self, x, y, title, clusters_ids):\n",
        "    trace1 = go.Bar(x = [i for i in clusters_ids],\n",
        "                  y=x,\n",
        "                  name='positives')\n",
        "    trace2 = go.Bar(x = [i for i in clusters_ids],\n",
        "                  y=y,\n",
        "                  name='negatives')\n",
        "    \n",
        "    self.data.append(trace1)\n",
        "    self.data.append(trace2)\n",
        "    \n",
        "    \n",
        "    button = dict(label=title,\n",
        "                 method='update',\n",
        "                 args=[{'visible':[False]*2*self.current_number_of_figures + \\\n",
        "                        [True, True] + \\\n",
        "                        [False]*2*(self.max_figures_available - self.current_number_of_figures-1)},\n",
        "                      {'title': title,\n",
        "                      'annotations':[]}])\n",
        "    self.buttons.append(button)\n",
        "    self.current_number_of_figures+=1\n",
        "    \n",
        "  def create_visualization(self):\n",
        "    updatemenus = list([dict(type='buttons',\n",
        "                            active=-1,\n",
        "                            buttons = self.buttons)])\n",
        "    \n",
        "    layout = go.Layout(barmode='group', updatemenus=updatemenus)\n",
        "    fig = dict(data=self.data, layout=layout)\n",
        "    plot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XyQ0F9ysZFgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_of_files = 3\n",
        "vis = plot_statistics(number_of_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wzd2xNMpOkdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_one_iteration(path_to_texts, path_to_sentiment, output_filename):\n",
        "  one = lda(path_to_texts, path_to_sentiment, True)\n",
        "  one.create_vocab()\n",
        "  one.vectorize_texts()\n",
        "  one.train_ldamodel(num_topics = 5, chunksize = 2000, epochs = 1, steps = 100)\n",
        "  print('model for {n} trained successfully'.format(n=output_filename))\n",
        "  one.write_clusterring_t0_html_file(output_filename)\n",
        "  print('file for {n} is ready'.format(n = output_filename))\n",
        "  one.get_cluster_distribution_and_sentiment()\n",
        "  one.grab_general_statistic()\n",
        "  titles = input().split(':')\n",
        "  one.rename_clusters(titles)\n",
        "  x, y, clusters_ids = one.return_statistics_for_ploting()\n",
        "  vis.add_one_more_bank(x, y, output_filename, clusters_ids)\n",
        "  print('statistic is updated')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9OwdKJRZDt1G",
        "colab_type": "code",
        "outputId": "e9436db2-dde5-402f-9ad7-61e2c5307d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/sentences_replies.pkl'\n",
        "path_ = '/content/gdrive/My Drive/banki ru csv/otpbank_sentimented.csv'\n",
        "make_one_iteration(path, path_, 'otpbank')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model for otpbank trained successfully\n",
            "file for otpbank is ready\n",
            "кредиты:платежы по кредитам:ресепшн:отделения:погашение кредитов\n",
            "statistic is updated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P3dl-RYMzk3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vis.create_visualization()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlMti_n622G_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}