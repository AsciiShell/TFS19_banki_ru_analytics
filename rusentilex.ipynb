{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "#топ банков по активам (не нашел россельхоз банк)\n",
    "bank_list = ['sberbank', 'vtb', 'gazprombank', 'vtb24', 'alfabank', 'fk_otkritie', 'mkb']\n",
    "bank_info_folder = 'TopicModelingFintech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_banks(folder_with_archives, bank_list):\n",
    "    for bank in bank_list:\n",
    "        path_to_zip_file = folder_with_archives + '/' + bank + '.tar.gz'\n",
    "        if os.path.isfile(path_to_zip_file):\n",
    "            if not os.path.isdir(folder_with_archives + '/' + bank):\n",
    "                tar = tarfile.open(path_to_zip_file, 'r')\n",
    "                tar.extractall(folder_with_archives)\n",
    "                tar.close()\n",
    "        else:\n",
    "            print(f'{bank} not found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_banks(bank_info_folder, bank_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разметка тональности предложений\n",
    "\n",
    "Разметим с помощью пакета deeppavlov разметим каждое предложение из отзывов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка Русентилекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_lines = []\n",
    "with open('rusentilex.txt', mode='r') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num < 18:\n",
    "            continue\n",
    "        read_lines.append([word.strip() for word in line.split(',')[:5]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>normalized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аборт</td>\n",
       "      <td>Noun</td>\n",
       "      <td>аборт</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>абортивный</td>\n",
       "      <td>Adj</td>\n",
       "      <td>абортивный</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>абракадабра</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абракадабра</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абсурд</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абсурд</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абсурдность</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абсурдность</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word part_of_speech   normalized sentiment   source\n",
       "0        аборт           Noun        аборт  negative     fact\n",
       "1   абортивный            Adj   абортивный  negative     fact\n",
       "2  абракадабра           Noun  абракадабра  negative  opinion\n",
       "3       абсурд           Noun       абсурд  negative  opinion\n",
       "4  абсурдность           Noun  абсурдность  negative  opinion"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusentilex = pd.DataFrame(read_lines, columns=['word', 'part_of_speech', 'normalized', 'sentiment', 'source'])\n",
    "rusentilex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(bank_info_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sberbank\n",
      "2019-04-21 19:17:36.947656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a86c9b91294fa4a1782c4a0322c400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8b973d27b843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtemp_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindWholeWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mtemp_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                         \u001b[0mtemp_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def findWholeWord(w):\n",
    "    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search\n",
    "\n",
    "sentiment = []\n",
    "for name in bank_list:\n",
    "    if os.path.isdir(name):\n",
    "        print(name)\n",
    "        print(datetime.datetime.now())\n",
    "        cur_path = os.path.join(os.getcwd(), name, 'sentences_replies.pkl')\n",
    "        sentences_replies = pd.read_pickle(cur_path)\n",
    "        column = 'vocab_only'\n",
    "        sentiment = pd.DataFrame(sentences_replies[column][:12_000])\n",
    "\n",
    "        for tonality in ['negative', 'positive']:\n",
    "            check_list = np.unique(rusentilex[rusentilex.sentiment == tonality].word)\n",
    "            temp_list = np.zeros(len(sentiment[column]))\n",
    "            for word in tqdm_notebook(check_list):\n",
    "                temp_func = findWholeWord(word)\n",
    "                for pos, text in enumerate(sentiment[column]):\n",
    "                    if temp_func(text):\n",
    "                        temp_list[pos] += 1\n",
    "                \n",
    "            sentiment[tonality] = temp_list\n",
    "        \n",
    "        sentiment.drop(column, axis=1, inplace=True)\n",
    "        sentiment.to_pickle(os.path.join(os.path.join(os.getcwd(), name, name + '_sentiment.pkl')))\n",
    "# sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "\n",
    "def make_sentiment_zip(dest_folder):\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(), dest_folder)):\n",
    "        os.makedirs(os.path.join(os.getcwd(), dest_folder))            \n",
    "    for name in os.listdir():\n",
    "        file_name = os.path.join(os.getcwd(), name, name + '_sentiment.pkl')\n",
    "        if os.path.isfile(file_name):\n",
    "            copyfile(file_name, os.path.join(os.getcwd(), dest_folder, name + '_sentiment.pkl'))\n",
    "  \n",
    "    make_tarfile(dest_folder + '.tar.gz', dest_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sentiment_zip('sentilex_banki')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
